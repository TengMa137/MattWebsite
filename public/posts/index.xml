<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Welcome</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on Welcome</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Fri, 30 Aug 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hungarian Algorithm in multiple object tracking</title>
      <link>http://localhost:1313/posts/2024-8-30-km/</link>
      <pubDate>Fri, 30 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024-8-30-km/</guid>
      <description>&lt;p&gt;Facilitated by the development of deep learning in subfields of computer vision including single object tracking (SOT), video object detection (VOD), and re-identification (Re-ID), many methods of multi-object tracking (MOT) have emerged, such as various embedding models designed for object locations and track identities [1]. While tracking-by-detection is still an effective paradigm for MOT, since we can always combine off-the-shelf state-of-the-art detectors and Re-ID models to improve the MOT system. The idea is: detect the objects in the current frame, then try to associate the detected boxes with tracked boxes in the previous frames. In practice, we need a more sophisticated design (e.g. choose similarity indices for data association, use Kalman Filter to predict new locations of tracks etc.) and proper strategies (e.g. to delete or initialize tracks). Hunarian algorithm is commonly used to matching objects after we get the similarity matrix, in this blog, I will try to explain how and why Hunarian algorithm works from the perspective of linear programming.&lt;br&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLMs Inference speed up EP1 - kv cache</title>
      <link>http://localhost:1313/posts/2024-5-30-kvcache/</link>
      <pubDate>Fri, 31 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024-5-30-kvcache/</guid>
      <description>&lt;p&gt;Large Language Models (LLMs) have revolutionized the field of natural language processing, enabling significant advancements in tasks such as language translation, text summarization, and sentiment analysis. However, despite their impressive capabilities, LLMs are not without limitations. One of the most significant challenges facing LLMs today is the problem of inference speed. Due to the sheer size and complexity of these models, the process of making predictions or extracting information from them can be computationally expensive and time-consuming. Several ways to speed up the LLMs without updating hardware: &lt;br&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>DIY - a multi-platform AI assistant</title>
      <link>http://localhost:1313/posts/2024-4-4-chatbot/</link>
      <pubDate>Wed, 03 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024-4-4-chatbot/</guid>
      <description>&lt;p&gt;This blog records how I explored building a personal AI assistant step by step, integrating ASR and TTS modules into LLM and deploying them on PC and mobile phones.&lt;/p&gt;&#xA;&lt;h1 id=&#34;build-a-local-chatbot-using-langchain&#34;&gt;&#xA;  Build a local chatbot using langchain&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#build-a-local-chatbot-using-langchain&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Large Language Models (LLM) have surprised us in many ways, such as talking like human, processing paper work, codeing copilot, analyzing data&amp;hellip;, simply by predicting the next token using probability model. As the LLMs get smarter and lighter, we can leverage LLMs that are close to or even surpasse the capabilities of ChatGPT on our device, which is going to make our life much easier. This blog shows how to build a chatbot that runs 100% locally and shares my thoughts on how the LLMs can help in our daily life.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Diffusion Probabilistic Models</title>
      <link>http://localhost:1313/posts/2024-3-14-ddpm/</link>
      <pubDate>Thu, 14 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2024-3-14-ddpm/</guid>
      <description>&lt;p&gt;Diffusion probabilistic models, or diffusion models for brevity are first proposed in [1]. The modified version called Denoising diffusion probabilistic models (DDPM) [2] were popularized due to the excellent high quality samples they generated, and Latent Diffusion Models (LDM) [3] make diffusion models practical. &lt;br&gt;&#xA;As a generative model, A DM models complex datasets in a computational tractable way [1]. Specificly, inspired by non-equilibrium statistical physics, a diffusion model first uses a parameterized Markov chain to gradually convert one distribution to another, usually gradually adds noise to the data to convert a very complex distribution to a simple one, e.g. normal distribution. Then it uses trainable Markov chain to reconstruct the target distribution from a simple known distribution.  &lt;br&gt;&#xA;Here an image $x_0 \sim q(x_0)$ is transitioned to an noisy image $x_t$ over $t$ timesteps by applying the Markov diffusion kernel $q(x_t|x_{t-1})$, or forward diffusion kernel. In the reverse process, $x_t$ is converted back to the target image $x_0$ by using the reverse diffusion kernel $p_\theta (x_t|x_{t-1})$, where $\theta$ represents trainable parameters.&#xA;&lt;br&gt;&#xA;&lt;img src=&#39;http://localhost:1313/images/img/DDPM.png&#39; alt=&#34;DDPM&#34;&gt;&#xA;&lt;br&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Variational Autoencoder explained</title>
      <link>http://localhost:1313/posts/2023-12-31-vae/</link>
      <pubDate>Sun, 31 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2023-12-31-vae/</guid>
      <description>&lt;p&gt;Variational Autoencoders (VAEs) are a powerful class of generative models used in unsupervised learning, combining the strengths of both neural networks and probabilistic models. They aim to approximate an underlying latent space that represents the distribution of data. To achieve this, VAEs learn to encode high-dimensional input data into a lower dimensional set of latent variables using a variational inference process. By doing so, they can reconstruct the original input while also enabling manipulation and generation of new samples within the learned distribution. This is particularly useful for applications like image synthesis, where the ability to encode complex data and then decode it as new variations of that data is crucial.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Supervised Learning EP2 - An introduction to Deep Learning</title>
      <link>http://localhost:1313/posts/2023-10-10-dl/</link>
      <pubDate>Tue, 10 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2023-10-10-dl/</guid>
      <description>&lt;p&gt;Deep learning is a subfield of machine learning that involves training artificial neural networks with multiple layers to analyze and solve complex problems. These neural networks are capable of learning hierarchical representations of data, enabling them to extract features and patterns from raw input data. Deep learning has been used in a wide range of applications such as image recognition, natural language processing, and autonomous driving. This blog covers the basics of four different types of DL models, paves the way to further in-depth study of various DNN.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Error state Kalman Filter</title>
      <link>http://localhost:1313/posts/2023-8-2-eskf/</link>
      <pubDate>Wed, 02 Aug 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2023-8-2-eskf/</guid>
      <description>&lt;p&gt;Error state is the difference between True state $x_t$ and Nominal state $x$. The nominal state does not take into account the noise, just derived from motion equations. As a result there will be accumulate errors, which are collected in the error-state $\delta x$ and the ESKF will estimate these errors. In parallel with integration of the nominal state, the ESKF predicts a Gaussian estimate of the error-state, and inject the mean of error state back to nominal-state. &lt;br&gt;When the IMU measurement data arrives, we integrate it and put it into the nominal state variable. Since this approach does not consider noise, the result will naturally drift quickly, so we hope to put the error part as an error variable in ESKF. ESKF will consider the effects of various noises and zero offsets, and give a Gaussian distribution description of the error state. At the same time, ESKF itself, as a Kalman filter, also has a prediction process and a correction process, and the correction process needs to rely on sensor observations other than the IMU. After the correction, ESKF can give the posterior error Gaussian distribution, and then we can put this part of the error into the nominal state variable, and set ESKF to zero, thus completing a loop.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kalman Filter explained with derivation</title>
      <link>http://localhost:1313/posts/2023-7-24-kf/</link>
      <pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2023-7-24-kf/</guid>
      <description>&lt;p&gt;Kalman Filter (KF) is a recursive state estimator widely used in sensor/data fusion. It&amp;rsquo;s an optimal Bayesian filter in linear Gaussian system, since it minimizes the estimated error covariance. It is also known as Gaussian Filter. KF is not applicable to discrete or hybrid state spaces. This blog helps understand Kalman Filter with simple examples and presents mathematical derivation from two different perspectives.&lt;/p&gt;&#xA;&lt;h1 id=&#34;modeling-robot-state-estimation&#34;&gt;&#xA;  Modeling Robot State Estimation&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#modeling-robot-state-estimation&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;details&gt;&lt;summary&gt;CLICK ME&lt;/summary&gt;&#xD;&#xA;&lt;p&gt;Now we want to estimate the state of a robot &amp;lt;$p, v$&amp;gt;, $p = [p_x, p_y, p_z]^T$ for position and $v = [v_x, v_y, v_z]^T$ for velocity. The state at time $k-1$ is $x_{k-1}=(p_{k-1},v_{k-1})$, we can predict the state at time $k$ if the accelaration $a_k$ is given:&#xA;$$&#xA;p_k = p_{k-1}+v_{k-1} \Delta t + \frac{1}{2}a_k (\Delta t)^2 \&#xA;v_k = v_{k-1}+a_k \Delta t&#xA;$$&#xA;In matrix form:&#xA;$$&#xA;x_k = Ax_{k-1}+Ba_k&#xA;$$&#xA;where $A$ is state transition matrix and $B$ is called control input matrix.&#xA;$$&#xA;A = \begin{bmatrix}1 &amp;amp; \Delta t \ 0 &amp;amp; 1 \end{bmatrix},&#xA;B = \begin{bmatrix} \frac{1}{2}(\Delta t)^2 \ \Delta t \end{bmatrix}&#xA;$$&#xA;This is the ideal case. In reality the robot is disturbed by so-called process noise, which models the uncertainty introduced by the state transition. Usually we assume the process noise $\omega_k$ follows a Gaussian distribution (it has to be Gaussian in KF) with zero mean $\omega_k \sim N(0,Q_k)$, $Q_k$ is the covariance matrix. Another observation of the state $z_k$ comes from sensor such as GPS, with measurement noise in Gaussian $v_k \sim N(0, R_k)$. State space model:&#xA;&lt;div class=&#34;math&#34;&gt;&#xA;&#xD;&#xA;$$&#xD;&#xA;\begin{aligned}&#xD;&#xA;&amp;x_k = Ax_{k-1}+Ba_k+\omega_k \\&#xD;&#xA;&amp;z_k = Hx_k+v_k&#xD;&#xA;\end{aligned}&#xD;&#xA;$$&#xD;&#xA;&#xA;&lt;/div&gt;&#xA;&#xA;where $H_k$ is measurement matrix that map the state space into the observation space.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Supervised Learning EP1 - Classical ML Models Recap</title>
      <link>http://localhost:1313/posts/2023-7-14-ml/</link>
      <pubDate>Fri, 14 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2023-7-14-ml/</guid>
      <description>&lt;h1 id=&#34;what-is-machine-learning&#34;&gt;&#xA;  What is Machine Learning?&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#what-is-machine-learning&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;A concise definition from T. Mitchell: &amp;ldquo;A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E&amp;rdquo;. Regarding of what learning is,Herbert A. Simon once defined it as &amp;ldquo;the ability that a system improves the performance of itself by executing some process&amp;rdquo;. Machine learning is a data driven subject that applies machine learning models to data analyzation and prediction. Generally machine learning can be categorized into: supervised learning, unsupervised learning, reinforcement learning, semi-supervised learning and active learning. To design a machine learning system, basically we need to do the following tasks:&lt;br&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dev Tools basics - Git</title>
      <link>http://localhost:1313/posts/2023-7-4-git/</link>
      <pubDate>Tue, 04 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2023-7-4-git/</guid>
      <description>&lt;p&gt;Git is a distributed version control tool that runs on Linux, Unix, Mac and Windows. With the help of Git, you don&amp;rsquo;t have to manually record and save copies every time when the files are changed, or worry about file exchange and protection when working on big projects with others. This post introduces common usage of Git.&lt;/p&gt;&#xA;&lt;h1 id=&#34;installation&#34;&gt;&#xA;  Installation&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#installation&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Git installation on Linux is simple, just type &amp;ldquo;git&amp;rdquo; in terminal and follow the hint.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Get to know Point Cloud</title>
      <link>http://localhost:1313/posts/2023-01-14-pcd/</link>
      <pubDate>Sat, 14 Jan 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2023-01-14-pcd/</guid>
      <description>&lt;p&gt;This blog post go through the basics of point cloud data and related projects I have done, including point cloud registration, point cloud segmentation.&lt;/p&gt;&#xA;&lt;h1 id=&#34;basics-of-pcd&#34;&gt;&#xA;  Basics of PCD&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#basics-of-pcd&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Point cloud data contains information of a set of points in three-dimensional space. Each point is represented as a vector of its 3D Cartesian coordinates (x, y, z), plus other information such as color (RGB), reflection intensity (Intensity) etc. Point cloud data can be acquired from LiDAR, RADAR, RGB-D cameras, or derived from images using multi-view stereo vision algorithms. &lt;img src=&#39;http://localhost:1313/images/img/pcd/pcd_gt.png&#39; alt=&#34;A scan of LiDAR with annotations&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Steps to set docker environment</title>
      <link>http://localhost:1313/posts/2022-12-14-docker/</link>
      <pubDate>Wed, 14 Dec 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2022-12-14-docker/</guid>
      <description>&lt;p&gt;This is a blog post that records the steps to set environment before I successfully trained and run a deep learning model in a docker container. Docker offers an isolated environment for software and dependencies and ensure the application runs quickly and reliably from one computing environment to another, by using container technology. See the difference between docker container and virtual machine in &lt;a href=&#34;https://www.docker.com/resources/what-container/&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.docker.com/resources/what-container/&lt;/a&gt;.&#xA;Have docker installed on the host computer, build docker environment following steps below.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
